[{"content":"Dockerとは Dockerは、アプリケーションをコンテナという単位でパッケージ化し、どの環境でも同じように動作させることができる技術です。\nなぜDockerが必要なのか 1. 環境依存の問題を解決 「私の環境では動くのに\u0026hellip;」という問題を解決します。開発環境、テスト環境、本番環境で同じコンテナを使用することで、環境差異による問題を最小化できます。\n2. 軽量で高速 仮想マシンと比較して：\n起動が速い（数秒） リソース消費が少ない 同じホストで多数のコンテナを実行可能 基本的なDockerコマンド イメージの操作 1 2 3 4 5 6 7 8 # イメージの検索 docker search nginx # イメージのダウンロード docker pull nginx:latest # ローカルのイメージ一覧 docker images コンテナの操作 1 2 3 4 5 6 7 8 9 10 11 # コンテナの起動 docker run -d -p 8080:80 --name my-nginx nginx # 実行中のコンテナ確認 docker ps # コンテナの停止 docker stop my-nginx # コンテナの削除 docker rm my-nginx Dockerfileの基本 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # ベースイメージの指定 FROM node:18-alpine # 作業ディレクトリの設定 WORKDIR /app # 依存関係ファイルのコピー COPY package*.json ./ # 依存関係のインストール RUN npm ci --only=production # アプリケーションファイルのコピー COPY . . # ポートの公開 EXPOSE 3000 # アプリケーションの起動 CMD [\u0026#34;node\u0026#34;, \u0026#34;server.js\u0026#34;] Docker Composeで複数コンテナを管理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 version: \u0026#39;3.8\u0026#39; services: web: build: . ports: - \u0026#34;3000:3000\u0026#34; environment: - NODE_ENV=production depends_on: - db db: image: postgres:14 environment: - POSTGRES_DB=myapp - POSTGRES_USER=user - POSTGRES_PASSWORD=password volumes: - postgres_data:/var/lib/postgresql/data volumes: postgres_data: ベストプラクティス 1. マルチステージビルドの活用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # ビルドステージ FROM node:18-alpine AS builder WORKDIR /app COPY package*.json ./ RUN npm ci COPY . . RUN npm run build # 実行ステージ FROM node:18-alpine WORKDIR /app COPY --from=builder /app/dist ./dist COPY --from=builder /app/node_modules ./node_modules CMD [\u0026#34;node\u0026#34;, \u0026#34;dist/index.js\u0026#34;] 2. .dockerignoreの活用 1 2 3 4 5 6 7 node_modules npm-debug.log .git .gitignore README.md .env .vscode トラブルシューティング ディスク容量の問題 1 2 3 4 5 6 7 # 未使用のリソースを一括削除 docker system prune -a # 個別に削除 docker image prune docker container prune docker volume prune ログの確認 1 2 3 4 5 # コンテナログの確認 docker logs my-container # リアルタイムでログを追跡 docker logs -f my-container まとめ Dockerは現代のアプリケーション開発において欠かせないツールとなっています。基本的なコマンドから始めて、徐々に複雑な構成にチャレンジしていくことで、効率的な開発環境を構築できます。\n次回は、Kubernetesを使ったコンテナオーケストレーションについて解説予定です。\n","permalink":"https://tmy310.github.io/post/tech-docker-basics/","summary":"\u003ch2 id=\"dockerとは\"\u003eDockerとは\u003c/h2\u003e\n\u003cp\u003eDockerは、アプリケーションをコンテナという単位でパッケージ化し、どの環境でも同じように動作させることができる技術です。\u003c/p\u003e\n\u003ch2 id=\"なぜdockerが必要なのか\"\u003eなぜDockerが必要なのか\u003c/h2\u003e\n\u003ch3 id=\"1-環境依存の問題を解決\"\u003e1. 環境依存の問題を解決\u003c/h3\u003e\n\u003cp\u003e「私の環境では動くのに\u0026hellip;」という問題を解決します。開発環境、テスト環境、本番環境で同じコンテナを使用することで、環境差異による問題を最小化できます。\u003c/p\u003e","title":"Docker入門：コンテナ技術の基礎から実践まで"},{"content":"京都の紅葉シーズン 京都の紅葉は例年11月中旬から12月上旬が見頃です。今回は、定番スポットと穴場を組み合わせた1泊2日のモデルコースをご紹介します。\n1日目：東山エリア 朝：清水寺（6:00開門） 早朝の清水寺は人が少なく、朝日に照らされる紅葉が格別です。\nアクセス\n京都駅から市バス206系統で「五条坂」下車、徒歩10分 拝観料：400円 午前：高台寺〜圓徳院 豊臣秀吉の妻、北政所ゆかりの寺院。庭園の紅葉が見事です。\n見どころ\n臥龍池の水面に映る紅葉 ライトアップ期間中は夜間特別拝観あり ランチ：祇園でおばんざい 1 2 3 4 おすすめ店：「祇園 さゝ木」 - 京野菜を使った創作料理 - ランチコース：3,000円〜 - 予約推奨 午後：南禅寺〜哲学の道 南禅寺\n三門からの眺望が絶景 水路閣での写真撮影も人気 哲学の道\n約2kmの散策路 途中のカフェで休憩もおすすめ 夕方：永観堂（ライトアップ） 「もみじの永観堂」と呼ばれる紅葉の名所。\nライトアップ情報\n期間：11月上旬〜下旬 時間：17:30〜21:00 料金：600円 2日目：嵐山・嵯峨野エリア 早朝：竹林の小径 朝7時頃なら観光客も少なく、静寂な竹林を楽しめます。\n午前：天龍寺 世界遺産の庭園は、紅葉シーズンの必見スポット。\nおすすめポイント\n曹源池庭園の借景 早朝拝観（7:30〜）がおすすめ 嵐山の穴場スポット 宝厳院 天龍寺の塔頭で、秋の特別公開時のみ拝観可能。\n祇王寺 苔と紅葉のコントラストが美しい小さな寺院。\nランチ：湯豆腐 1 2 3 「嵯峨野 湯豆腐 嵐山よしむら」 - 嵐山を眺めながらの食事 - 湯豆腐セット：2,500円 午後：大覚寺 大沢池\n平安時代から変わらぬ風景 池の周囲約1kmの散策路 穴場の紅葉スポット 1. 鷺森神社（左京区） 参道の紅葉トンネルが圧巻 観光客が少ない隠れた名所 2. 曼殊院門跡（一乗寺） 枯山水庭園と紅葉の調和 静かに紅葉を楽しめる 3. 源光庵（鷹峯） 「悟りの窓」と「迷いの窓」から見る紅葉 哲学的な趣のある寺院 混雑回避のコツ 時間帯の工夫 早朝拝観：開門直後の6:00〜8:00 夕方：16:00以降は比較的空いている 平日：可能なら平日訪問がベスト 移動手段 自転車レンタル：渋滞を避けて効率的に移動 地下鉄・電車：バスより確実 徒歩：近距離なら歩いた方が早い場合も 持ち物リスト 歩きやすい靴（石段や坂道が多い） 防寒具（朝晩は冷え込む） モバイルバッテリー（写真撮影で電池消耗） 現金（寺社は現金のみの場合が多い） 宿泊のおすすめ エリア別の特徴 京都駅周辺\nアクセス便利 ビジネスホテル多数 祇園・東山\n観光地に近い 町家ゲストハウスあり 嵐山\n温泉旅館あり 朝の散策に便利 まとめ 京都の紅葉は確かに混雑しますが、時間帯と場所を工夫すれば、ゆったりと楽しむことができます。定番スポットと穴場を組み合わせて、自分だけの紅葉巡りコースを作ってみてください。\n次回は、冬の金沢での雪景色と温泉旅をご紹介予定です。\n","permalink":"https://tmy310.github.io/post/travel-kyoto-autumn/","summary":"\u003ch2 id=\"京都の紅葉シーズン\"\u003e京都の紅葉シーズン\u003c/h2\u003e\n\u003cp\u003e京都の紅葉は例年11月中旬から12月上旬が見頃です。今回は、定番スポットと穴場を組み合わせた1泊2日のモデルコースをご紹介します。\u003c/p\u003e\n\u003ch2 id=\"1日目東山エリア\"\u003e1日目：東山エリア\u003c/h2\u003e\n\u003ch3 id=\"朝清水寺600開門\"\u003e朝：清水寺（6:00開門）\u003c/h3\u003e\n\u003cp\u003e早朝の清水寺は人が少なく、朝日に照らされる紅葉が格別です。\u003c/p\u003e","title":"秋の京都散策：紅葉の名所巡りと穴場スポット"},{"content":"はじめに データ分析は現代のビジネスにおいて必須スキルとなっています。PythonとそのライブラリであるPandas、NumPy、Matplotlibを使えば、効率的にデータ分析を行うことができます。\n環境構築 必要なライブラリのインストール 1 pip install pandas numpy matplotlib seaborn jupyter Jupyter Notebookの起動 1 jupyter notebook NumPy：数値計算の基礎 配列の作成と操作 1 2 3 4 5 6 7 8 9 10 import numpy as np # 配列の作成 arr = np.array([1, 2, 3, 4, 5]) matrix = np.array([[1, 2, 3], [4, 5, 6]]) # 統計量の計算 print(f\u0026#34;平均: {arr.mean()}\u0026#34;) print(f\u0026#34;標準偏差: {arr.std()}\u0026#34;) print(f\u0026#34;最大値: {arr.max()}\u0026#34;) 行列演算 1 2 3 4 5 6 7 8 9 # 行列の積 A = np.array([[1, 2], [3, 4]]) B = np.array([[5, 6], [7, 8]]) # 要素ごとの積 element_wise = A * B # 行列積 matrix_product = A @ B Pandas：データ操作の要 DataFrameの基本操作 1 2 3 4 5 6 7 8 9 import pandas as pd # CSVファイルの読み込み df = pd.read_csv(\u0026#39;sales_data.csv\u0026#39;) # データの概要確認 print(df.head()) print(df.info()) print(df.describe()) データのフィルタリングと集計 1 2 3 4 5 6 7 8 9 10 11 12 13 # 条件によるフィルタリング high_sales = df[df[\u0026#39;売上\u0026#39;] \u0026gt; 100000] # グループ化と集計 monthly_sales = df.groupby(\u0026#39;月\u0026#39;)[\u0026#39;売上\u0026#39;].agg([\u0026#39;sum\u0026#39;, \u0026#39;mean\u0026#39;, \u0026#39;count\u0026#39;]) # ピボットテーブル pivot = df.pivot_table( values=\u0026#39;売上\u0026#39;, index=\u0026#39;商品カテゴリ\u0026#39;, columns=\u0026#39;地域\u0026#39;, aggfunc=\u0026#39;sum\u0026#39; ) 欠損値の処理 1 2 3 4 5 6 7 8 # 欠損値の確認 print(df.isnull().sum()) # 欠損値の補完 df[\u0026#39;価格\u0026#39;].fillna(df[\u0026#39;価格\u0026#39;].mean(), inplace=True) # 欠損値を含む行の削除 df_clean = df.dropna() Matplotlib：データの可視化 基本的なグラフ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 import matplotlib.pyplot as plt import matplotlib as mpl # 日本語フォントの設定 mpl.font_manager.fontManager.addfont(\u0026#39;/System/Library/Fonts/ヒラギノ角ゴシック W3.ttc\u0026#39;) plt.rcParams[\u0026#39;font.family\u0026#39;] = \u0026#39;Hiragino Sans\u0026#39; # 折れ線グラフ plt.figure(figsize=(10, 6)) plt.plot(df[\u0026#39;日付\u0026#39;], df[\u0026#39;売上\u0026#39;], marker=\u0026#39;o\u0026#39;) plt.title(\u0026#39;月別売上推移\u0026#39;) plt.xlabel(\u0026#39;月\u0026#39;) plt.ylabel(\u0026#39;売上（円）\u0026#39;) plt.grid(True) plt.show() 複数のグラフを組み合わせる 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 fig, axes = plt.subplots(2, 2, figsize=(12, 10)) # ヒストグラム axes[0, 0].hist(df[\u0026#39;価格\u0026#39;], bins=20, edgecolor=\u0026#39;black\u0026#39;) axes[0, 0].set_title(\u0026#39;価格分布\u0026#39;) # 散布図 axes[0, 1].scatter(df[\u0026#39;広告費\u0026#39;], df[\u0026#39;売上\u0026#39;]) axes[0, 1].set_title(\u0026#39;広告費 vs 売上\u0026#39;) # 箱ひげ図 axes[1, 0].boxplot([df[df[\u0026#39;地域\u0026#39;]==\u0026#39;東京\u0026#39;][\u0026#39;売上\u0026#39;], df[df[\u0026#39;地域\u0026#39;]==\u0026#39;大阪\u0026#39;][\u0026#39;売上\u0026#39;]]) axes[1, 0].set_xticklabels([\u0026#39;東京\u0026#39;, \u0026#39;大阪\u0026#39;]) axes[1, 0].set_title(\u0026#39;地域別売上分布\u0026#39;) # 円グラフ category_sales = df.groupby(\u0026#39;カテゴリ\u0026#39;)[\u0026#39;売上\u0026#39;].sum() axes[1, 1].pie(category_sales, labels=category_sales.index, autopct=\u0026#39;%1.1f%%\u0026#39;) axes[1, 1].set_title(\u0026#39;カテゴリ別売上構成\u0026#39;) plt.tight_layout() plt.show() 実践例：売上データの分析 データの準備 1 2 3 4 5 6 7 8 9 # サンプルデータの作成 np.random.seed(42) dates = pd.date_range(\u0026#39;2024-01-01\u0026#39;, periods=365) sales_data = pd.DataFrame({ \u0026#39;日付\u0026#39;: dates, \u0026#39;売上\u0026#39;: np.random.normal(100000, 20000, 365) + np.sin(np.arange(365) * 2 * np.pi / 365) * 30000, \u0026#39;広告費\u0026#39;: np.random.normal(10000, 2000, 365), \u0026#39;気温\u0026#39;: np.random.normal(20, 10, 365) }) 時系列分析 1 2 3 4 5 6 7 8 9 10 11 12 # 移動平均の計算 sales_data[\u0026#39;売上_7日移動平均\u0026#39;] = sales_data[\u0026#39;売上\u0026#39;].rolling(window=7).mean() sales_data[\u0026#39;売上_30日移動平均\u0026#39;] = sales_data[\u0026#39;売上\u0026#39;].rolling(window=30).mean() # グラフ化 plt.figure(figsize=(14, 6)) plt.plot(sales_data[\u0026#39;日付\u0026#39;], sales_data[\u0026#39;売上\u0026#39;], alpha=0.3, label=\u0026#39;日次売上\u0026#39;) plt.plot(sales_data[\u0026#39;日付\u0026#39;], sales_data[\u0026#39;売上_7日移動平均\u0026#39;], label=\u0026#39;7日移動平均\u0026#39;) plt.plot(sales_data[\u0026#39;日付\u0026#39;], sales_data[\u0026#39;売上_30日移動平均\u0026#39;], label=\u0026#39;30日移動平均\u0026#39;) plt.legend() plt.title(\u0026#39;売上推移と移動平均\u0026#39;) plt.show() 相関分析 1 2 3 4 5 6 7 8 9 10 # 相関係数の計算 correlation_matrix = sales_data[[\u0026#39;売上\u0026#39;, \u0026#39;広告費\u0026#39;, \u0026#39;気温\u0026#39;]].corr() # ヒートマップで可視化 import seaborn as sns plt.figure(figsize=(8, 6)) sns.heatmap(correlation_matrix, annot=True, cmap=\u0026#39;coolwarm\u0026#39;, center=0) plt.title(\u0026#39;変数間の相関係数\u0026#39;) plt.show() データ分析のベストプラクティス 1. データの前処理は丁寧に 欠損値の確認と処理 外れ値の検出と対処 データ型の確認と変換 2. 可視化は目的に応じて 分布を見る：ヒストグラム、箱ひげ図 関係性を見る：散布図、相関行列 推移を見る：折れ線グラフ 構成を見る：円グラフ、積み上げ棒グラフ 3. 再現性の確保 1 2 3 4 5 6 # 乱数のシード固定 np.random.seed(42) # バージョン情報の記録 print(f\u0026#34;pandas: {pd.__version__}\u0026#34;) print(f\u0026#34;numpy: {np.__version__}\u0026#34;) まとめ Pythonでのデータ分析は、pandas、NumPy、Matplotlibの3つのライブラリを使いこなすことから始まります。基本的な操作を習得したら、実際のデータセットで練習を重ねることが上達への近道です。\n次回は、scikit-learnを使った機械学習入門について解説予定です。\n","permalink":"https://tmy310.github.io/post/tech-python-data-analysis/","summary":"\u003ch2 id=\"はじめに\"\u003eはじめに\u003c/h2\u003e\n\u003cp\u003eデータ分析は現代のビジネスにおいて必須スキルとなっています。PythonとそのライブラリであるPandas、NumPy、Matplotlibを使えば、効率的にデータ分析を行うことができます。\u003c/p\u003e","title":"Pythonでデータ分析入門：pandas、NumPy、Matplotlibの基礎"},{"content":"長野県松本市に1泊2日の旅行に行ってきました。初日は、松本城を訪れ、その壮大な姿に感動。歴史的な城郭の美しさに囲まれながら、城内の展示をじっくりと見学しました。周辺の城下町も散策し、地元のカフェでそばを楽しみました。\n2日目は、上高地へ向かい、澄んだ空気と美しい山々を満喫。大自然の中を歩くことで、心も体もリフレッシュできました。美しい景色の写真や動画を以下にリンクしていますので、ぜひご覧ください。\n動画はこちら\n","permalink":"https://tmy310.github.io/post/travel2/","summary":"\u003cp\u003e長野県松本市に1泊2日の旅行に行ってきました。初日は、松本城を訪れ、その壮大な姿に感動。歴史的な城郭の美しさに囲まれながら、城内の展示をじっくりと見学しました。周辺の城下町も散策し、地元のカフェでそばを楽しみました。\u003c/p\u003e","title":"大阪から長野県松本への1泊2日の旅行"},{"content":"長野県松本市に1泊2日の旅行に行ってきました。初日は、松本城を訪れ、その壮大な姿に感動。歴史的な城郭の美しさに囲まれながら、城内の展示をじっくりと見学しました。周辺の城下町も散策し、地元のカフェでそばを楽しみました。\n2日目は、上高地へ向かい、澄んだ空気と美しい山々を満喫。大自然の中を歩くことで、心も体もリフレッシュできました。美しい景色の写真や動画を以下にリンクしていますので、ぜひご覧ください。\n動画はこちら\n","permalink":"https://tmy310.github.io/post/travel/","summary":"\u003cp\u003e長野県松本市に1泊2日の旅行に行ってきました。初日は、松本城を訪れ、その壮大な姿に感動。歴史的な城郭の美しさに囲まれながら、城内の展示をじっくりと見学しました。周辺の城下町も散策し、地元のカフェでそばを楽しみました。\u003c/p\u003e","title":"長野県松本への1泊2日の旅行"},{"content":"ブログ開設！ この度、ブログをはじめました。\n技術ネタ、趣味や備忘録などを不定期でブログを書いていきます。\n自動デプロイシステムも構築完了しました！\nよろしくどーぞ！\n","permalink":"https://tmy310.github.io/post/my-first-post/","summary":"\u003ch2 id=\"ブログ開設\"\u003eブログ開設！\u003c/h2\u003e\n\u003cp\u003eこの度、ブログをはじめました。\u003c/p\u003e\n\u003cp\u003e技術ネタ、趣味や備忘録などを不定期でブログを書いていきます。\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e自動デプロイシステムも構築完了しました！\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eよろしくどーぞ！\u003c/p\u003e","title":"ブログはじめました"},{"content":"はじめに これは太字のテキスト、そしてこれは斜体のテキストです。\nHugoのウェブサイトをご覧ください！\nPaperModテーマを使って、モダンなブログデザインになりました。\n","permalink":"https://tmy310.github.io/posts/my-first-post/","summary":"\u003ch2 id=\"はじめに\"\u003eはじめに\u003c/h2\u003e\n\u003cp\u003eこれは\u003cstrong\u003e太字\u003c/strong\u003eのテキスト、そしてこれは\u003cem\u003e斜体\u003c/em\u003eのテキストです。\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://gohugo.io\"\u003eHugo\u003c/a\u003eのウェブサイトをご覧ください！\u003c/p\u003e\n\u003cp\u003ePaperModテーマを使って、モダンなブログデザインになりました。\u003c/p\u003e","title":"はじめてのブログ投稿"},{"content":"ナレッジ項目：DeepDiff を用いたBigQueryスキーマ比較とPythonオブジェクトの扱い 今回のやり取りでは、DeepDiff を使ってBigQueryスキーマ（google.cloud.bigquery.SchemaField オブジェクト）の差分を正確に検出する過程で、いくつかの重要なポイントが明らかになりました。\nPythonオブジェクトの「内部構造」とDeepDiffの比較対象 Pythonの属性アクセスの特性: Pythonでは、アンダースコア（_）で始まる変数やメソッドは「プライベート」という慣習的な意味合いを持つだけであり、言語レベルでの強制的なアクセス制限（カプセル化）は存在しません。つまり、コード上はどこからでもアクセス可能です。 DeepDiff の挙動: DeepDiff は、オブジェクトの深い（Deep）な差分を検出するため、単に公開されている属性 (obj.attr) だけでなく、オブジェクトが内部的にデータを保持している辞書 (obj.dict や SchemaField の _properties など）の内容も比較対象とします。これは、オブジェクトがどのような形でデータを保持していようと、Pythonの標準的なメカニズムで参照可能であれば、比較対象に含まれるためです。 BigQuery SchemaField の具体例: SchemaField オブジェクトには、公開属性としての policy_tags と、内部的な _properties 辞書内の \u0026lsquo;policyTags\u0026rsquo; という2つの経路でポリシータグ情報が保持されています。DeepDiff はこれら両方を比較対象とするため、片方を除外しただけでは差分が残り得ます。 DeepDiff のexclude_obj_callbackの適切な利用 特定の属性を除外する要件: 「policy_tags の変更はスキーマの差分として検出したくない」というビジネス要件を満たすために、DeepDiff のカスタマイズ機能である exclude_obj_callback が非常に有効です。 精密な除外ロジック: exclude_obj_callback は、比較対象から除外したい「値」に到達したときにのみ True を返すように、精密なロジックを組む必要があります。 isinstance(obj, PolicyTagList): SchemaField.policy_tags のように、DeepDiff が比較対象の obj を PolicyTagList インスタンスそのものとして渡してきた場合に除外する条件。 path.endswith(\u0026quot;[\u0026lsquo;policyTags\u0026rsquo;]\u0026quot;): _properties 辞書内の \u0026lsquo;policyTags\u0026rsquo; キーのように、obj が PolicyTagList インスタンスではない辞書型の一部として渡された場合でも、特定のパスに合致すれば除外する条件。 冗長性の排除: if condition: return True else: return False というパターンは return condition に置き換えることで、コードをより簡潔（Pythonic）に記述できます（RuffのSIM103ルール）。 コールバック関数の位置づけと命名 ヘルパー関数の役割: _exclude_policy_tags_callback は、DeepDiff の特定機能 (exclude_obj_callback) を利用するための補助的な役割を果たすため、「ヘルパー関数」として位置づけられます。 ビジネスロジックのサポート: このヘルパー関数は、「特定の差分（ポリシータグ）を無視する」という具体的なビジネス要件を実現するため、ビジネスロジックの一部をサポートしているとも言えます。 クラスメソッドとしての適切性: もしスキーマ比較ロジック全体が特定のクラスの責務であるならば、このコールバック関数をそのクラスのプライベートメソッド（exclude\u0026hellip;）として定義するのは、カプセル化とコードのまとまりの点で適切です。 flatten_schema_fields との比較: flatten_schema_fields のような、特定のデータ構造を汎用的に変換する関数も、メインのビジネスロジックを簡素化する点で典型的な「ヘルパー関数」です。 DeepDiff の出力の読み方と活用 DeepDiff の出力は、values_changed, iterable_item_added, iterable_item_removed などのセクションに分かれ、変更されたパスと新旧の値が詳細に示されます。 この出力は、プログラムでの自動解析に適した辞書形式であると同時に、DeepDiff オブジェクトの pretty() メソッドを使用することで、人間が視覚的に確認しやすい整形された形式で表示することも可能です。 これらのナレッジ項目は、DeepDiff を BigQuery スキーマの比較に応用するだけでなく、他の複雑なPythonオブジェクトの差分検出や、特定の要件に基づいた比較ロジックを構築する際にも役立つでしょう。 このナレッジ項目で、今回の学びが整理できたでしょうか？他に何か追加すべき点や、さらに深掘りしたい点があれば教えてください。\npythonにおいてはDeepdiffでよいように思えました。typescript、java、php、rubyでも似たようなものがありますか？\nそういえば、noteなどdeepdiff以外にも聞いたことがあったかと思います。それもナレッジとして抽出してください。\nはい、承知いたしました。DeepDiff 以外にも、オブジェクトやデータの差分検出に関連して言及される可能性のある概念やツールをナレッジとして抽出します。これらは直接 DeepDiff の代替となるライブラリでなくても、似たような文脈で議論されるものです。\nナレッジ項目：DeepDiff 以外の差分検出・比較に関連する概念とツール Pythonにおける DeepDiff はオブジェクトの構造的な差分検出に優れていますが、他にも様々なレベルや目的で差分を扱う概念やツールが存在します。\nバージョン管理システム (Git, SVNなど) 目的: ファイルやコードベース全体の変更履歴を管理し、異なるバージョン間の差分（diff）を追跡します。 特徴: 通常、テキストベースの差分（行の追加、削除、変更）を検出します。 コードレビュー、変更履歴の追跡、共同開発に不可欠です。 バイナリファイルの変更も追跡できますが、中身の差分を表示することはできません。 DeepDiff との関連: Git diff はファイル間の差分を検出しますが、DeepDiff はプログラム内のメモリ上にあるオブジェクト構造の差分を検出します。用途が異なります。 テキスト差分ツール (diff, Beyond Compare, WinMerge, kdiff3など) 目的: 2つのテキストファイルやディレクトリ間の差分を視覚的に表示し、マージを支援します。 特徴: ラインベースの比較が基本です。 プログラミングコード、設定ファイル、ドキュメントなどの比較によく使われます。 高度なツールは、ディレクトリ比較、3者間マージ、構文ハイライトなどを提供します。 DeepDiff との関連: これらはファイルの内容を文字列として比較するのに対し、DeepDiff はPythonオブジェクトの内部構造（辞書、リスト、カスタムクラスの属性など）をプログラム的に比較します。 データ比較・検証ライブラリ（Python: pandas.testing, numpy.testingなど） 目的: 特定のデータ構造（例: DataFrame, NumPy配列）における値の比較や、近似値の許容範囲での比較を行います。 特徴: データサイエンスや数値計算の文脈で、計算結果の一致性検証やテストに利用されます。 浮動小数点数の誤差を許容する比較などが可能です。 DeepDiff との関連: DeepDiff は汎用的なオブジェクト構造の比較に重点を置くのに対し、これらは特定のデータ型に特化しており、多くの場合、より厳密な数値比較や統計的な比較機能を提供します。 オブジェクトの等価性チェック（言語組み込み） 目的: 2つのオブジェクトが「等しい」と見なせるかどうかを判断します。 特徴: Pythonの == 演算子、Javaの .equals() メソッド、JavaScriptの === 演算子などが該当します。 デフォルトでは、参照の等価性（同じメモリ上のオブジェクトか）や、クラスが定義する基本的な値の等価性をチェックします。 「深い等価性」の概念: オブジェクトがネストされた構造を持つ場合、その内部の全要素が等しいかどうかを再帰的にチェックする「深い等価性」の概念が重要になります。DeepDiff はこの「深い等価性」が満たされない場合に、その理由（差分）を詳細に報告するツールと言えます。 DeepDiff との関連: DeepDiff は、単に等しいか否かだけでなく、「どこが、どのように違うのか」を詳細に知りたい場合に利用されます。多くの言語の標準ライブラリには、DeepDiff のような詳細な差分報告機能は含まれていません。 APIレスポンス比較ツール / スキーマ検証ツール 目的: APIからのJSON/XMLレスポンスや、データ構造が期待されるスキーマ（例: JSON Schema）と一致するかを検証します。 特徴: テスト自動化やAPI監視でよく利用されます。 フィールドの存在、型、制約などをチェックします。 一部のツールは、レスポンス間の差分を検出する機能も持ちます。 DeepDiff との関連: 今回のBigQueryスキーマ比較のように、PythonオブジェクトとしてAPIレスポンスを扱える場合、DeepDiff を用いてレスポンスオブジェクト間の詳細な差分を検出することは可能です。スキーマ検証は「型が合っているか」に主眼を置くのに対し、DeepDiff は「内容が一致するか」に主眼を置きます。 これらのツールや概念は、それぞれ異なるレベルや目的でデータの「変更」や「違い」を扱います。DeepDiff は特に、プログラム内で扱う複雑なPythonオブジェクトの構造的な差分を、詳細かつプログラム的に検出・報告するというニッチで強力な役割を担っている、という位置づけになります。 違います。noteとはどういうものか？ヘルパーとはどういうものか？などをきいたと思います。\nご指摘いただきありがとうございます。私の理解が不足しておりました。\n「note」とはどういうものか、そして「ヘルパー」とはどういうものか、といった概念や定義についてのご質問でしたね。大変失礼いたしました。\n今回のやり取りを振り返り、それらの概念について明確にまとめ、今後のナレッジとさせていただきます。\nナレッジ項目：ソフトウェア開発における「ノート」と「ヘルパー」の概念 今回の会話では、特定のコードの役割やドキュメントに関する用語について議論がありました。これらの概念を明確にすることで、チーム内でのコミュニケーションやコードベースの理解が深まります。\n「ノート (Note)」の概念 会話の中で「noteなど」という形で出てきた「note」は、文脈によって複数の意味を持ち得ます。ソフトウェア開発においては、一般的に以下のような意味で使われることが多いです。 開発メモ/記録:\n開発中に個人やチームで記録する、非公式なメモや覚書のこと。 特定の設計上の決定、一時的な作業ログ、試行錯誤の過程、後で検討すべき事項などを指す場合があります。 コードのコメントとしてではなく、別途ドキュメントやWiki、プロジェクト管理ツールなどに記録されることが多いです。 目的は、将来の参照のためや、チームメンバー間での情報共有のためです。 コードコメント内の注意書き:\nソースコード内に書かれた、特定の処理や実装に関する注意点、警告、補足説明などを指す場合があります。 例えば、「FIXME」「TODO」「HACK」「NOTE」といった特殊なコメントタグとして使われ、特定のリンターやIDEで検出されることがあります。 今回の Docstring 内で「例:root[\u0026hellip;]._properties[\u0026lsquo;fields\u0026rsquo;][0][\u0026lsquo;policyTags\u0026rsquo;]」のように書かれた箇所は、関数の使用方法や挙動に関する「ノート（補足説明）」として機能しています。 今回の文脈では、後者の**「コードコメント内の補足説明や注意書き」、または一般的な「開発における記録やメモ」**といった意味合いで使われた可能性が高いと推測されます。\n「ヘルパー (Helper)」の概念 「ヘルパー」または「ヘルパー関数/メソッド」は、ソフトウェア開発において非常に一般的な用語です。 定義と目的:\n特定の、反復的または補助的なタスクを実行するために設計された関数やメソッドのこと。 メインのビジネスロジックを簡素化し、可読性を高める役割を担います。 主なビジネスロジックやコア機能から分離され、それらの機能を「助ける（help）」存在です。 通常、ヘルパー関数自体が複雑なビジネス判断を含むことは稀で、データの整形、計算、特定のAPIの呼び出しなど、より低レベルな操作を行うことが多いです。 主な特徴:\n再利用性: 複数の場所で同じような処理が必要になる場合に、コードの重複を防ぐために使われます。 モジュール性/カプセル化: 特定のタスクを独立した関数にまとめることで、コードベース全体のモジュール性が向上し、保守しやすくなります。 可読性の向上: メインのコードパスから詳細な実装を隠蔽することで、メインロジックの理解を容易にします。 今回の _exclude_policy_tags_callback および flatten_schema_fields との関連:\n_exclude_policy_tags_callback: DeepDiff という特定のライブラリのコールバックインターフェースに適合し、そのライブラリの動作をカスタマイズ（policy_tags の除外）する補助的な役割を担っています。これは、メインのスキーマ比較処理を「助ける」機能であり、ヘルパー関数と呼ぶのが適切です。同時に、そのカスタマイズ自体が「ポリシータグは無視する」というビジネス要件を満たすため、ビジネスロジックをサポートする側面も持ちます。 flatten_schema_fields: BigQueryの階層的な SchemaField オブジェクトを、DeepDiff で比較しやすいように「平坦化」という形に変換します。これは、データの「前処理」や「整形」という補助的なタスクであり、メインの比較ロジックをシンプルに保つために不可欠な機能であるため、これも典型的なヘルパー関数と言えます。 3. 用語の解釈とチーム内での合意 「ヘルパー関数」という用語の厳密な定義は存在せず、プロジェクトやチームのコーディング規約、文化、個人の解釈によって、その適用範囲や呼び方が異なることがあります。 例えば、ある人は汎用的なユーティリティ関数をヘルパーと呼び、別の人は特定のクラスに属する補助メソッドのみをヘルパーと呼ぶかもしれません。 最も重要なのは、チーム内でこれらの用語に関する共通の理解と合意を形成することです。コードの意図が明確に伝わり、一貫したスタイルが保たれることが、保守性の高いコードベースを構築する上で不可欠です。 このナレッジ項目で、ご質問いただいた概念がより明確になったでしょうか。\n他に会話の中でdeepdiff, note, ヘルパー以外でこれも知ったほうがいいことはありますか？\nはい、今回の会話の中で、DeepDiff、note、ヘルパー 以外にも、ソフトウェア開発全般、特にPythonを用いた開発やチーム開発において、知っておくと役立つ重要な概念やプラクティスがいくつかありました。\n以下にそれらをナレッジとして抽出します。\nナレッジ項目：ソフトウェア開発における重要概念とプラクティス\nPythonの「Pythonic（パイソニック）」なコーディングスタイル 概要: Pythonicとは、単に文法的に正しいだけでなく、Python言語の特性や慣習、思想に沿った、より簡潔で読みやすく、効率的なコードを書くことを指します。 具体例: 冗長な if/else の排除: if condition: return True else: return False を return condition と書く（今回のRuff SIM103 の指摘）。これは、条件式の結果がそのままブール値として返されることを利用したPythonicな書き方です。 リスト内包表記やジェネレータ式を活用する。 適切な命名規則（PEP 8）に従う。 なぜ重要か: コードの可読性、保守性、そしてPythonコミュニティでの一般的な理解度を高めます。リンター（Ruffなど）は、このようなPythonicな記述を推奨・強制するのに役立ちます。 リンター (Ruff など) の活用 概要: リンターは、ソースコードのスタイル、文法エラー、潜在的なバグなどを静的に（実行せずに）分析し、問題点を指摘するツールです。Ruff はPythonの高速なリンターとして注目されています。 役割: コーディング規約の統一: チーム内で一貫したコードスタイルを強制し、レビューの負担を減らします。 バグの早期発見: 実行時エラーにつながる可能性のある記述や、一般的な落とし穴を指摘します。 可読性・保守性の向上: Pythonicな書き方やベストプラクティスを推奨し、コード品質全体を向上させます。 なぜ重要か: 開発効率を高め、品質の高いコードを維持するために不可欠なツールです。CI/CDパイプラインに組み込むことで、コード品質を自動的にチェックできます。 Docstring（ドキュメンテーション文字列）の重要性 概要: Pythonの関数、クラス、モジュールに記述される複数行の文字列で、そのコードブロックの目的、引数、戻り値、例外などを説明するために使用されます。 役割: 自己文書化: コードの動作を理解するための最も直接的な情報源となります。 IDE/ツールとの連携: IDE（VS Code, PyCharmなど）がDocstringを解析し、関数の使い方や引数のヒントをポップアップ表示するなど、開発体験を向上させます。 自動ドキュメント生成: Sphinxなどのツールを用いて、DocstringからAPIリファレンスドキュメントを自動生成できます。 なぜ重要か: コードの可読性と保守性を飛躍的に向上させ、特にチーム開発や長期プロジェクトにおいて、新しいメンバーのオンボーディングや既存コードの理解を容易にします。Docstringのスタイル（Googleスタイル、NumPyスタイルなど）を統一することも重要です。 カプセル化と内部構造の扱い 概要: オブジェクト指向プログラミングの主要な原則の一つで、オブジェクトの内部状態や実装詳細を外部から隠蔽し、公開されたインターフェース（メソッドや公開属性）を通じてのみアクセスさせることです。 Pythonにおける特性: Pythonでは、アンダースコア（_）で始まる属性は「内部的である」という慣習を示すものであり、他の言語のような厳密なアクセス制限はありません。これは「大人のプログラミング」と呼ばれます。 DeepDiff との関連: DeepDiff は、このPythonの特性を活かして、_properties のような内部属性にもアクセスして比較します。これにより、意図せず変更された内部状態も検出できますが、逆に除外したい場合は明示的な設定（exclude_obj_callback など）が必要になります。 なぜ重要か: コードの変更による影響範囲を限定し、保守性を高めます。しかし、DeepDiff のように内部に踏み込むツールを使う際は、そのツールの挙動とカプセル化の概念との兼ね合いを理解しておく必要があります。 要件定義とテストの重要性（特に差分検出において） 概要: 何を「差分」と見なすか、何を「無視」するかという要件を明確に定義し、それがテストで正しく検証されていることを確認するプロセス。 今回のケース: policy_tags の変更は「無視する」という要件を明確にし、それが DeepDiff のコールバック関数で正しく機能しているかを実際のログで確認しました。 なぜ重要か: 複雑なデータ構造の比較では、「何が重要で、何が無視できる変更なのか」というビジネスルールが曖昧になりがちです。これを明確にすることで、意図しない変更を検出し、必要な変更のみを適切に扱うことができます。テスト駆動開発（TDD）のアプローチも有効です。 これらの概念は、個々のコード実装の技術的な詳細を超えて、より良いソフトウェアを開発し、チームとして効率的に働くための基盤となるものです。 ","permalink":"https://tmy310.github.io/post/blog-copy/","summary":"\u003cp\u003eナレッジ項目：DeepDiff を用いたBigQueryスキーマ比較とPythonオブジェクトの扱い\n今回のやり取りでは、DeepDiff を使ってBigQueryスキーマ（google.cloud.bigquery.SchemaField オブジェクト）の差分を正確に検出する過程で、いくつかの重要なポイントが明らかになりました。\u003c/p\u003e","title":""},{"content":"⏺ 記事1: VPC Service ControlsでのGitHub Actions対応：エラーベース権限設定のベストプラクティス\nはじめに\nGoogle Cloud の VPC Service Controls（VPC-SC）を enforced mode で運用している環境で、GitHub Actions による Terraform 実行が突然失敗するようになった経験はありませんか？\n本記事では、VPC-SC 違反エラーの解決にエラーベース権限設定というアプローチを用いて、セキュリティを保ちながら効率的に権限を設定 する方法を解説します。\n問題の背景\nVPC Service Controls が dry-run mode から enforced mode に移行すると、今まで動いていた GitHub Actions ワークフローが以下のようなエラーで失敗するようになります：\nError 403: Request is prohibited by organization\u0026rsquo;s policy. vpcServiceControlsUniqueIdentifier: xxxxx\nこれは、GitHub Actions の Workload Identity Federation で使用するサービスアカウントが、VPC-SC で保護されたリソースにアクセスできなくなったためです。\nエラーベース権限設定とは\n従来のアプローチでは、事前に「必要そうな権限」をすべて付与することが多かったのですが、エラーベース権限設定では：\n最小限の権限でスタート 実際にエラーが発生したタイミングで権限を追加 エラーログから必要な権限を正確に特定 このアプローチにより、真に必要な権限のみを付与することができます。\n実践：エラーログの読み方\nVPC-SC違反が発生すると、Cloud Logging に詳細なエラーログが記録されます：\n{ \u0026ldquo;protoPayload\u0026rdquo;: { \u0026ldquo;serviceName\u0026rdquo;: \u0026ldquo;storage.googleapis.com\u0026rdquo;, \u0026ldquo;methodName\u0026rdquo;: \u0026ldquo;google.storage.buckets.testIamPermissions\u0026rdquo;, \u0026ldquo;authenticationInfo\u0026rdquo;: { \u0026ldquo;principalEmail\u0026rdquo;: \u0026ldquo;github-actions-plan@project.iam.gserviceaccount.com\u0026rdquo; } } }\nこのログから以下の情報を読み取れます：\n対象サービス: storage.googleapis.com 必要なメソッド: google.storage.buckets.testIamPermissions エラーの主体: GitHub Actions のサービスアカウント VPC-SC Ingress Policy の設定\nエラーログをもとに、ingress policy を設定します：\nresource \u0026ldquo;google_access_context_manager_service_perimeter_ingress_policy\u0026rdquo; \u0026ldquo;github_actions\u0026rdquo; { perimeter = var.service_perimeter_name\ningress_from { identities = [ \u0026quot;serviceAccount:github-actions-plan@project.iam.gserviceaccount.com\u0026quot;, \u0026quot;serviceAccount:github-actions-apply@project.iam.gserviceaccount.com\u0026quot; ] sources { access_level = \u0026quot;*\u0026quot; # GitHub Actions の IP は動的 } } ingress_to { resources = [\u0026quot;projects/123456789\u0026quot;] operations { service_name = \u0026quot;storage.googleapis.com\u0026quot; method_selectors { method = \u0026quot;google.storage.buckets.testIamPermissions\u0026quot; } } } }\n段階的な権限追加の実例\nTerraform での一般的な権限追加パターン：\n初期設定（Terraform state 管理） operations { service_name = \u0026ldquo;storage.googleapis.com\u0026rdquo; method_selectors { method = \u0026ldquo;google.storage.objects.list\u0026rdquo; method = \u0026ldquo;google.storage.objects.get\u0026rdquo; method = \u0026ldquo;google.storage.buckets.get\u0026rdquo; } }\nエラー発生後の追加 operations { service_name = \u0026ldquo;storage.googleapis.com\u0026rdquo; method_selectors { method = \u0026ldquo;google.storage.objects.create\u0026rdquo; # state更新用 method = \u0026ldquo;google.storage.buckets.testIamPermissions\u0026rdquo; # 権限確認用 } }\nBigQuery リソース管理 operations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.create\u0026rdquo; permission = \u0026ldquo;bigquery.tables.create\u0026rdquo; } }\nベストプラクティス\nログ監視の自動化 VPC-SC違反を監視するクエリ例 gcloud logging read ' protoPayload.metadata.\u0026quot;@type\u0026quot;=\u0026ldquo;type.googleapis.com/google.cloud.audit.VpcServiceControlAuditMetadata\u0026rdquo; AND protoPayload.authenticationInfo.principalEmail:\u0026ldquo;github-actions\u0026rdquo; \u0026rsquo; \u0026ndash;format=\u0026ldquo;json\u0026rdquo;\n権限の文書化 エラーベースで追加した権限は、なぜその権限が必要なのかをコメントで記録：\noperations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { # Terraform での dataset 存在確認に必要 permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; # BigQuery audit log sink の作成に必要 permission = \u0026ldquo;bigquery.datasets.create\u0026rdquo; } }\n定期的な権限見直し 使用されていない権限を定期的にチェック：\n過去30日の API 使用状況を確認 gcloud logging read ' protoPayload.serviceName=\u0026ldquo;bigquery.googleapis.com\u0026rdquo; AND protoPayload.authenticationInfo.principalEmail:\u0026ldquo;github-actions\u0026rdquo; AND timestamp\u0026gt;=\u0026ldquo;2024-01-01\u0026rdquo; \u0026rsquo; \u0026ndash;format=\u0026ldquo;table(protoPayload.methodName)\u0026rdquo;\nまとめ\nエラーベース権限設定は、VPC Service Controls 環境での権限管理において：\nセキュリティ向上: 最小権限の原則を実践 運用効率化: 不要な権限調査時間を削減 透明性確保: 権限付与の根拠が明確 GitHub Actions と VPC-SC の組み合わせでお困りの際は、ぜひこのアプローチを試してみてください。\n記事2: Google CloudサービスのVPC Service Controls対応状況：メソッド指定の罠と対策\nはじめに\nVPC Service Controls（VPC-SC）で ingress/egress policy を設定する際、サービスによってメソッド指定の対応状況が大きく異なることをご存知でしょうか？\n本記事では、実際に遭遇したエラーから学んだ、Google Cloud サービス別のメソッド指定対応状況と、それぞれの対策方法を詳しく解説します。\nVPC-SC でのメソッド指定の基本\nVPC-SC の ingress/egress policy では、以下の2つの方法でアクセス権限を指定できます：\nPermissions 指定 operations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.tables.create\u0026rdquo; } }\nMethods 指定 operations { service_name = \u0026ldquo;storage.googleapis.com\u0026rdquo; method_selectors { method = \u0026ldquo;google.storage.objects.get\u0026rdquo; method = \u0026ldquo;google.storage.buckets.list\u0026rdquo; } }\nサービス別対応状況一覧\n実際に検証した結果、サービスごとに対応状況が大きく異なることが判明しました：\nサービス 個別メソッド指定 対応形式 備考 storage.googleapis.com ✅ フルパス google.storage.objects.get bigquery.googleapis.com ✅ permissions/methods併用 用途により使い分け logging.googleapis.com ✅ 短縮形式 ConfigServiceV2.GetSink monitoring.googleapis.com ❌ * のみ 個別指定不可 secretmanager.googleapis.com ❌ * のみ 個別指定不可 datacatalog.googleapis.com ❌ * のみ 個別指定不可 実際のエラーパターンと対策\nパターン1: フルパス指定が必要なケース\nエラー例（Storage）: Error 400: METHOD \u0026lsquo;objects.get\u0026rsquo; is not supported in storage.googleapis.com\n対策:\n❌ 短縮形式 method = \u0026ldquo;objects.get\u0026rdquo;\n✅ フルパス指定 method = \u0026ldquo;google.storage.objects.get\u0026rdquo;\nパターン2: 短縮形式でないとエラーになるケース\nエラー例（Logging）: Error 400: METHOD \u0026lsquo;google.logging.v2.ConfigServiceV2.GetSink\u0026rsquo; is not supported in logging.googleapis.com\n対策:\n❌ フルパス method = \u0026ldquo;google.logging.v2.ConfigServiceV2.GetSink\u0026rdquo;\n✅ 短縮形式 method = \u0026ldquo;ConfigServiceV2.GetSink\u0026rdquo;\nパターン3: 個別指定が一切サポートされないケース\nエラー例（Monitoring）: Error 400: METHOD \u0026lsquo;NotificationChannelService.GetNotificationChannel\u0026rsquo; is not supported in monitoring.googleapis.com\n対策:\n❌ 個別メソッド指定 method = \u0026ldquo;NotificationChannelService.GetNotificationChannel\u0026rdquo;\n✅ ワイルドカード使用 method = \u0026ldquo;*\u0026rdquo;\nBigQuery の特殊ケース\nBigQuery は permissions と methods の使い分けが重要です：\nPermissions を使用するケース\noperations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { # データセット・テーブル操作 permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.tables.create\u0026rdquo; } }\nMethods を使用するケース\noperations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { # 特定の API 呼び出し method = \u0026ldquo;DatasetService.InsertDataset\u0026rdquo; method = \u0026ldquo;TableDataService.InsertAll\u0026rdquo; } }\nIAM 操作の罠\nBigQuery での IAM 操作は特に注意が必要です：\n❌ BigQuery サービス内でのIAM指定（エラーになる） operations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { permission = \u0026ldquo;bigquery.datasets.getIamPolicy\u0026rdquo; # サポート外 method = \u0026ldquo;google.iam.v1.IAMPolicy.GetIamPolicy\u0026rdquo; # サポート外 } }\n✅ 実際にはBigQueryの標準権限で処理される operations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.update\u0026rdquo; } }\n効率的な調査方法\nエラーメッセージからの推測 エラーメッセージのパターンで対応状況を推測：\nパターン1: フルパス不足 \u0026ldquo;METHOD \u0026lsquo;objects.get\u0026rsquo; is not supported\u0026rdquo; → google.storage.objects.get を試す\nパターン2: フルパス過多 \u0026ldquo;METHOD \u0026lsquo;google.logging.v2.ConfigServiceV2.GetSink\u0026rsquo; is not supported\u0026rdquo; → ConfigServiceV2.GetSink を試す\nパターン3: 個別指定不可 \u0026ldquo;METHOD \u0026lsquo;NotificationChannelService.GetNotificationChannel\u0026rsquo; is not supported\u0026rdquo; → \u0026ldquo;*\u0026rdquo; を使用\n段階的テスト戦略 Step 1: 具体的メソッドを試す method = \u0026ldquo;SpecificMethod.Action\u0026rdquo;\nStep 2: 短縮形式を試す method = \u0026ldquo;Action\u0026rdquo;\nStep 3: ワイルドカードにフォールバック method = \u0026ldquo;*\u0026rdquo;\nドキュメント確認 Google Cloud のドキュメントで対応状況を確認：\nhttps://cloud.google.com/vpc-service-controls/docs/supported-services 各サービスの API リファレンス まとめとベストプラクティス\n対応状況の把握\nStorage/BigQuery: 詳細な制御が可能 Logging: 短縮形式で制御可能 Monitoring/SecretManager: ワイルドカードのみ 設定時の推奨手順\n具体的なメソッド指定から開始 エラーに応じて形式を調整 最終手段として * を使用 設定理由をコメントで文書化 コメント記載例\noperations { service_name = \u0026ldquo;monitoring.googleapis.com\u0026rdquo; method_selectors { method = \u0026ldquo;*\u0026rdquo; # 個別のメソッドは未サポート } }\nVPC Service Controls の複雑な仕様に惑わされず、段階的なアプローチで効率的に設定を進めていきましょう。\n記事3: Terraformプロバイダーから読み解く必要なGoogle Cloud権限設計\nはじめに\nTerraform で Google Cloud リソースを管理する際、「どの権限が本当に必要なのか？」という疑問を持ったことはありませんか？\n特に VPC Service Controls 環境では、過不足ない権限設定が重要になります。本記事では、Terraform のリソース定義から必要な Google Cloud 権限を逆算し、効率的な権限設計を行う方法を解説します。\n基本的な考え方\nTerraformリソース ≠ 必要権限 多くの場合、Terraform の1つのリソースを管理するために複数の Google Cloud 権限が必要になります：\nresource \u0026ldquo;google_bigquery_dataset\u0026rdquo; \u0026ldquo;example\u0026rdquo; { dataset_id = \u0026ldquo;example_dataset\u0026rdquo; location = \u0026ldquo;US\u0026rdquo; }\nこのシンプルなリソースでも、実際には以下の権限が必要：\nbigquery.datasets.get (状態確認) bigquery.datasets.create (作成) bigquery.datasets.update (更新) CRUD操作の分析 Terraform の操作フローから必要権限を導き出せます：\nTerraform操作 必要なGoogle Cloud権限 terraform plan Read権限 (*.get, *.list) terraform apply (作成) Create権限 (*.create) terraform apply (更新) Update権限 (*.update, *.patch) terraform destroy Delete権限 (*.delete) 実践例1: BigQuery Dataset管理\nTerraformリソース定義\nresource \u0026ldquo;google_bigquery_dataset\u0026rdquo; \u0026ldquo;analytics\u0026rdquo; { dataset_id = \u0026ldquo;analytics\u0026rdquo; friendly_name = \u0026ldquo;Analytics Dataset\u0026rdquo; description = \u0026ldquo;Dataset for analytics data\u0026rdquo; location = \u0026ldquo;US\u0026rdquo;\n# データセットアクセス制御 access { role = \u0026quot;OWNER\u0026quot; special_group = \u0026quot;projectOwners\u0026quot; } access { role = \u0026quot;READER\u0026quot; user_by_email = \u0026quot;analyst@example.com\u0026quot; } }\n必要権限の分析\n基本的なデータセット操作:\nVPC-SC Policy設定例 operations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; # plan時の状態確認 permission = \u0026ldquo;bigquery.datasets.create\u0026rdquo; # 初回作成 permission = \u0026ldquo;bigquery.datasets.update\u0026rdquo; # 設定変更 } }\nアクセス制御の罠:\n多くの人が見落とすのが、access ブロックによる IAM 操作です：\n❌ 不十分な権限設定 permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.create\u0026rdquo;\n✅ IAM操作も含めた完全な設定 permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.create\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.update\u0026rdquo;\naccess ブロックの変更には update 権限が必要 実践例2: BigQuery Dataset Access管理\nより複雑なケース\nresource \u0026ldquo;google_bigquery_dataset_access\u0026rdquo; \u0026ldquo;analyst_access\u0026rdquo; { dataset_id = google_bigquery_dataset.analytics.dataset_id role = \u0026ldquo;READER\u0026rdquo; user_by_email = \u0026ldquo;analyst@example.com\u0026rdquo; }\nresource \u0026ldquo;google_bigquery_dataset_access\u0026rdquo; \u0026ldquo;service_account_access\u0026rdquo; { dataset_id = google_bigquery_dataset.analytics.dataset_id role = \u0026ldquo;WRITER\u0026rdquo; user_by_email = \u0026ldquo;service-account@project.iam.gserviceaccount.com\u0026rdquo; }\n権限設計\noperations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { # データセット基本操作 permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.update\u0026rdquo; # access変更に必要\n# IAM操作（dataset_access リソース用） # 注意: BigQueryのIAM操作は特殊で、標準的なIAM権限ではなく # BigQuery固有の権限で制御される } }\n実践例3: テーブル作成を含むケース\nTerraformリソース\nresource \u0026ldquo;google_bigquery_table\u0026rdquo; \u0026ldquo;user_events\u0026rdquo; { dataset_id = google_bigquery_dataset.analytics.dataset_id table_id = \u0026ldquo;user_events\u0026rdquo;\ntime_partitioning { type = \u0026quot;DAY\u0026quot; field = \u0026quot;event_timestamp\u0026quot; } schema = jsonencode([ { name = \u0026quot;user_id\u0026quot; type = \u0026quot;STRING\u0026quot; mode = \u0026quot;REQUIRED\u0026quot; }, { name = \u0026quot;event_timestamp\u0026quot; type = \u0026quot;TIMESTAMP\u0026quot; mode = \u0026quot;REQUIRED\u0026quot; } ]) }\n拡張された権限設計\noperations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { # データセット操作（依存関係で必要） permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo;\n# テーブル操作 permission = \u0026quot;bigquery.tables.get\u0026quot; # plan時の確認 permission = \u0026quot;bigquery.tables.create\u0026quot; # 作成 permission = \u0026quot;bigquery.tables.update\u0026quot; # スキーマ変更等 permission = \u0026quot;bigquery.tables.list\u0026quot; # 依存関係確認 } }\n実践例4: ロギング設定を含む複合ケース\nTerraformリソース\nresource \u0026ldquo;google_logging_project_sink\u0026rdquo; \u0026ldquo;bigquery_sink\u0026rdquo; { name = \u0026ldquo;bigquery-audit-sink\u0026rdquo; destination = \u0026ldquo;bigquery.googleapis.com/projects/${var.project}/datasets/${google_bigquery_dataset.audit_logs.dataset_id}\u0026rdquo; filter = \u0026ldquo;resource.type=bigquery_resource\u0026rdquo; unique_writer_identity = true }\nresource \u0026ldquo;google_bigquery_dataset\u0026rdquo; \u0026ldquo;audit_logs\u0026rdquo; { dataset_id = \u0026ldquo;audit_logs\u0026rdquo; location = \u0026ldquo;US\u0026rdquo;\n# Sink からの書き込み用アクセス access { role = \u0026quot;WRITER\u0026quot; user_by_email = google_logging_project_sink.bigquery_sink.writer_identity } }\nマルチサービス権限設計\nBigQuery権限 operations { service_name = \u0026ldquo;bigquery.googleapis.com\u0026rdquo; method_selectors { permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.create\u0026rdquo; permission = \u0026ldquo;bigquery.datasets.update\u0026rdquo; } }\nLogging権限 operations { service_name = \u0026ldquo;logging.googleapis.com\u0026rdquo; method_selectors { method = \u0026ldquo;ConfigServiceV2.GetSink\u0026rdquo; # sink状態確認 method = \u0026ldquo;ConfigServiceV2.CreateSink\u0026rdquo; # sink作成 method = \u0026ldquo;ConfigServiceV2.UpdateSink\u0026rdquo; # sink更新 } }\n権限設計のベストプラクティス\n段階的な権限付与戦略 Phase 1: 基本的な読み取り権限 permission = \u0026ldquo;bigquery.datasets.get\u0026rdquo; permission = \u0026ldquo;bigquery.tables.get\u0026rdquo;\nPhase 2: 作成権限（初回apply時に追加） permission = \u0026ldquo;bigquery.datasets.create\u0026rdquo; permission = \u0026ldquo;bigquery.tables.create\u0026rdquo;\nPhase 3: 更新権限（設定変更時に追加） permission = \u0026ldquo;bigquery.datasets.update\u0026rdquo; permission = \u0026ldquo;bigquery.tables.update\u0026rdquo;\n依存関係の理解 テーブル作成にはデータセット読み取り権限も必要 resource \u0026ldquo;google_bigquery_table\u0026rdquo; \u0026ldquo;example\u0026rdquo; { dataset_id = google_bigquery_dataset.example.dataset_id # この参照により必要 table_id = \u0026ldquo;example_table\u0026rdquo; }\n必要権限: - bigquery.datasets.get (依存関係確認) - bigquery.tables.create (テーブル作成) 環境別の権限調整 locals { # 開発環境：より多くの権限 dev_permissions = [ \u0026ldquo;bigquery.datasets.get\u0026rdquo;, \u0026ldquo;bigquery.datasets.create\u0026rdquo;, \u0026ldquo;bigquery.datasets.update\u0026rdquo;, \u0026ldquo;bigquery.datasets.delete\u0026rdquo;, # 開発では削除も許可 \u0026ldquo;bigquery.tables.get\u0026rdquo;, \u0026ldquo;bigquery.tables.create\u0026rdquo;, \u0026ldquo;bigquery.tables.update\u0026rdquo;, \u0026ldquo;bigquery.tables.delete\u0026rdquo; ]\n# 本番環境：最小権限 prod_permissions = [ \u0026quot;bigquery.datasets.get\u0026quot;, \u0026quot;bigquery.datasets.update\u0026quot;, # 設定変更のみ \u0026quot;bigquery.tables.get\u0026quot;, \u0026quot;bigquery.tables.update\u0026quot; # スキーマ変更のみ ] }\n検証とモニタリング\n権限使用状況の確認 実際に使用された権限の確認 gcloud logging read ' protoPayload.serviceName=\u0026ldquo;bigquery.googleapis.com\u0026rdquo; AND protoPayload.authenticationInfo.principalEmail:\u0026ldquo;terraform-service-account\u0026rdquo; AND timestamp\u0026gt;=TIMESTAMP_FROM_RFC3339(\u0026ldquo;2024-01-01T00:00:00Z\u0026rdquo;) \u0026rsquo; \u0026ndash;format=\u0026ldquo;table(protoPayload.methodName, protoPayload.authorizationInfo.permission)\u0026rdquo;\n不要権限の特定 付与されているが使用されていない権限を特定 gcloud projects get-iam-policy PROJECT_ID \u0026ndash;flatten=\u0026ldquo;bindings[].members\u0026rdquo; \u0026ndash;filter=\u0026ldquo;bindings.members:terraform-service-account\u0026rdquo; \u0026ndash;format=\u0026ldquo;table(bindings.role)\u0026rdquo;\nまとめ\nTerraform リソースから Google Cloud 権限を設計する際のポイント：\nリソース定義の詳細分析: 単純なリソースでも複数の権限が必要 依存関係の考慮: 参照されるリソースの読み取り権限も必要 段階的な権限付与: plan → apply → update の流れに沿って権限を追加 環境別の調整: 開発と本番で異なる権限レベルを設定 継続的な見直し: 実際の使用状況に基づく権限の最適化 適切な権限設計により、セキュリティを保ちながら効率的な Terraform 運用が実現できます。\n","permalink":"https://tmy310.github.io/post/blog/","summary":"\u003cp\u003e⏺ 記事1: VPC Service ControlsでのGitHub Actions対応：エラーベース権限設定のベストプラクティス\u003c/p\u003e\n\u003cp\u003eはじめに\u003c/p\u003e\n\u003cp\u003eGoogle Cloud の VPC Service Controls（VPC-SC）を enforced mode で運用している環境で、GitHub Actions による Terraform\n実行が突然失敗するようになった経験はありませんか？\u003c/p\u003e","title":""}]