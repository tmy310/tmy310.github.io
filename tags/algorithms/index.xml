<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Algorithms on firebirdãƒ†ã‚¯ãƒ†ã‚¯ãƒ†ã‚¯ãƒ–ãƒ­ã‚°</title>
        <link>https://firebird-techtalktech.com/tags/algorithms/</link>
        <description>Recent content in Algorithms on firebirdãƒ†ã‚¯ãƒ†ã‚¯ãƒ†ã‚¯ãƒ–ãƒ­ã‚°</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>ja</language>
        <copyright>ãƒˆãƒŸãƒ¼</copyright>
        <lastBuildDate>Sun, 14 Sep 2025 14:54:52 +0900</lastBuildDate><atom:link href="https://firebird-techtalktech.com/tags/algorithms/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>ğŸ“š Fractal-Down</title>
        <link>https://firebird-techtalktech.com/post/fractal-down/</link>
        <pubDate>Sun, 14 Sep 2025 14:54:52 +0900</pubDate>
        
        <guid>https://firebird-techtalktech.com/post/fractal-down/</guid>
        <description>&lt;h2 id=&#34;è¨˜äº‹æ¦‚è¦&#34;&gt;è¨˜äº‹æ¦‚è¦
&lt;/h2&gt;&lt;p&gt;Fractal-Down is a Python package for evaluating computational DAGs with square-root memory complexity&amp;hellip;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;å‡ºå…¸&lt;/strong&gt;: &lt;a class=&#34;link&#34; href=&#34;https://dev.to/nrd_inc/fractal-down-4dl9&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dev.to&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;åé›†æ—¥æ™‚&lt;/strong&gt;: 2025-09-14T14:54:45.414354&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.to/nrd_inc/fractal-down-4dl9&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ğŸ”— å…ƒè¨˜äº‹ã‚’èª­ã‚€&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        <item>
        <title>ğŸ“š How does low-rank adaptation for large language models work</title>
        <link>https://firebird-techtalktech.com/post/how-does-low-rank-adaptation-for-large-language-models-work/</link>
        <pubDate>Sun, 14 Sep 2025 14:54:52 +0900</pubDate>
        
        <guid>https://firebird-techtalktech.com/post/how-does-low-rank-adaptation-for-large-language-models-work/</guid>
        <description>&lt;h2 id=&#34;è¨˜äº‹æ¦‚è¦&#34;&gt;è¨˜äº‹æ¦‚è¦
&lt;/h2&gt;&lt;p&gt;Table of Contents    Why study LoRA? The challenge of fine-tuning massive models Conceptual&amp;hellip;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;å‡ºå…¸&lt;/strong&gt;: &lt;a class=&#34;link&#34; href=&#34;https://dev.to/lewis_won/how-do-low-rank-adaptation-of-large-language-models-work-3ga6&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Dev.to&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;åé›†æ—¥æ™‚&lt;/strong&gt;: 2025-09-14T14:54:46.642703&lt;/p&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dev.to/lewis_won/how-do-low-rank-adaptation-of-large-language-models-work-3ga6&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ğŸ”— å…ƒè¨˜äº‹ã‚’èª­ã‚€&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
